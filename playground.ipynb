{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "def draw_image(image):\n",
    "    return PIL.Image.fromarray((np.array(image) * 255).astype(np.uint8))\n",
    "\n",
    "\n",
    "def read_nii_file(path):\n",
    "    nifti = nib.load(path)\n",
    "    data_array = nifti.get_data()\n",
    "    affine_matrix = nifti.affine\n",
    "    return data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_15148/2005157495.py:29: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  image = np_data[slc]\n",
      "100%|██████████| 22/22 [00:51<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import monai\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def nifti_to_2d_slices(input_folder: str, output_folder: str, axis: int, filtered, resize):\n",
    "    for fname in tqdm(sorted(os.listdir(input_folder))):\n",
    "\n",
    "        if not fname.endswith(\"nii.gz\"):\n",
    "            continue\n",
    "\n",
    "        n_file = os.path.join(input_folder, fname)\n",
    "        nifti = nib.load(n_file)\n",
    "\n",
    "        np_data = nifti.get_fdata()\n",
    "        np_data = np_data.astype(np.float16)\n",
    "        # np_data.shape (512, 512, 120)\n",
    "\n",
    "        f_basename = fname.split(\".\")[0]\n",
    "\n",
    "        for i in range(np_data.shape[axis]):\n",
    "            slc = [slice(None)] * len(np_data.shape)\n",
    "            \n",
    "            slc[axis] = i\n",
    "            image = np_data[slc]\n",
    "            # image.shape (512, 512)\n",
    "\n",
    "            if resize:\n",
    "                tr = monai.transforms.Resize((resize, resize))\n",
    "                image = tr(image[None])[0]\n",
    "\n",
    "            if filtered:\n",
    "                brain_mask = image > 0\n",
    "                if brain_mask.sum() < 4000:\n",
    "                    continue\n",
    "\n",
    "            np.save(os.path.join(output_folder, f\"{f_basename}_{i}.npy\"), image)\n",
    "\n",
    "\n",
    "input_dir = r\"data\\train\"\n",
    "output_dir = r\"data\\out\"\n",
    "axis = 2\n",
    "do_filter = False\n",
    "resize = 256\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "nifti_to_2d_slices(input_dir, output_dir, axis, do_filter, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_15148/1041683615.py:14: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  data_array = nifti.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 512, 120])\n"
     ]
    }
   ],
   "source": [
    "res = read_nii_file(f'{input_dir}/crossmoda2021_ldn_1_ceT1.nii.gz')\n",
    "\n",
    "#anw = np.array(res)\n",
    "#print(res.dtype)\n",
    "res = res.astype(float)\n",
    "#writer = SummaryWriter(\"logs\")\n",
    "np_data = torch.tensor(res).unsqueeze(0)\n",
    "print(np_data.shape)\n",
    "#monai.visualize.img2tensorboard.plot_2d_or_3d_image(np_data,writer=writer,step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "numpy_array = np.load('data/out\\crossmoda2021_ldn_1_ceT1_1.npy')\n",
    "numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\AppDL\\crossmoda-challenge\\datasets.py:102: RuntimeWarning: overflow encountered in multiply\n",
      "  image = PIL.Image.fromarray((np.array(image) * 255).astype(np.uint8))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from datasets import DatasetType\n",
    "from datasets import DATASETS\n",
    "from transforms import TRANSFORMS\n",
    "with open('train_example.yaml', 'r') as stream:\n",
    "    config = yaml.load(stream, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_type = config['train_dataset']['dataset_type']\n",
    "dataset_kwargs = config['train_dataset']['dataset_kwargs']\n",
    "transform_kwargs = config['train_dataset']['transform_kwargs']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = TRANSFORMS[DatasetType[dataset_type]](**transform_kwargs)\n",
    "dataset = DATASETS[DatasetType['numpy2d']](\n",
    "    transform=transform,\n",
    "    **dataset_kwargs\n",
    ")\n",
    "\n",
    "dl = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True, pin_memory=False)\n",
    "\n",
    "next(iter(dl)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\AppDL\\crossmoda-challenge\\datasets.py:102: RuntimeWarning: overflow encountered in multiply\n",
      "  image = PIL.Image.fromarray((np.array(image) * 255).astype(np.uint8))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('uqdl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c764c3311b97f6e5910658da22a6fb9fd9ff2faa94a18237546e57a4f156fdc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
